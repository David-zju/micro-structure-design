input vector:
geometry
|f1|f2|t1|t2|
|--|--|--|--|
|(p1,p2,p3,p4)|(p1,p2,p3,p4)|t1|t2|

condition
|E|G|v|Type|
|--|--|--|--|
|E|G|v|onehot{i1,i2,i3,i4,i5,i6}|


### 2023/4/22
- [x] 几何信息的更新 
- [x] 输出了第一版数据，但是出现了很多负数，感觉训练数据中-1这一项会对神经网络产生影响？  
    如何对-1进行处理(先置0)
- [x] 数值范围需要限定，例如厚度不能太厚，以及$p_i$的值在0-10范围内  
  现在是在损失函数内加了1项，其中权重到时候需要再调整调整，目前如果将-1改成0之后训练数据都落在0-10这个范围内了，所以直接做损失函数也没有意义
- [ ] 
### 2023/4/24
今天发现还是有负数，开始溯源
通过激活函数的修改使其能够不出现负值
其次，添加第一层的unet连接（up4与x），并更新了中间几层的feature的值
在输出层添加了GroupNorm层（但愿能有用）
---
晚上检查后发现还是没有用的，思考，是否应该输出直接加一个Relu层，但是这是无济于事的，因为实际上是采样的过程生成样本，而不是网络直接去学（这个不是gan）
先在图像上做做试验，发现如果采样时间步长如果很短，那么输出的图片就会像是散点图（10 vs 500），那么怎么样才能评估超参数呢？

跟师姐讨论了一下，模型确实可能会有问题，但是先试试超参数上的调整
最后的方案是使用模型的种类来训练，不使用扩散模型，直接插值

查看图像生成的代码，torchvision里面有个make_grid函数，会对输出的tensor归一化，然后*255，那么我们也可以对我们的输出数据进行归一化，然后*一个我们自己的scaler，先试试看