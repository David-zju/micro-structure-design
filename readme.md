input vector:
geometry
|f1|f2|t1|t2|
|--|--|--|--|
|(p1,p2,p3,p4)|(p1,p2,p3,p4)|t1|t2|

condition
|E|G|v|Type|
|--|--|--|--|
|E|G|v|onehot{i1,i2,i3,i4,i5,i6}|


### 2023/4/22
- [x] 几何信息的更新 
- [x] 输出了第一版数据，但是出现了很多负数，感觉训练数据中-1这一项会对神经网络产生影响？  
    如何对-1进行处理(先置0)
- [x] 数值范围需要限定，例如厚度不能太厚，以及$p_i$的值在0-10范围内  
  现在是在损失函数内加了1项，其中权重到时候需要再调整调整，目前如果将-1改成0之后训练数据都落在0-10这个范围内了，所以直接做损失函数也没有意义
- [ ] 
### 2023/4/24
今天发现还是有负数，开始溯源
通过激活函数的修改使其能够不出现负值
其次，添加第一层的unet连接（up4与x），并更新了中间几层的feature的值
在输出层添加了GroupNorm层（但愿能有用）

---
晚上检查后发现还是没有用的，思考，是否应该输出直接加一个Relu层，但是这是无济于事的，因为实际上是采样的过程生成样本，而不是网络直接去学（这个不是gan）
先在图像上做做试验，发现如果采样时间步长如果很短，那么输出的图片就会像是散点图（10 vs 500），那么怎么样才能评估超参数呢？

跟师姐讨论了一下，模型确实可能会有问题，但是先试试超参数上的调整
最后的方案是使用模型的种类来训练，不使用扩散模型，直接插值

查看图像生成的代码，torchvision里面有个make_grid函数，会对输出的tensor归一化，然后*255，那么我们也可以对我们的输出数据进行归一化，然后*一个我们自己的scaler，先试试看

### 2023/4/25
早上与师姐讨论，师姐有个想法是通过神经网络输出的值域来控制逆采样过程的$x_t$的值域，可能需要验证一下数学公式上是否满足这个性质
区分坐标的0和没有面片的0，坐标+10->[10,20]
坐标的输入也归一化一下
今天看了一下，make_grid函数实际上没有启用归一化，是save_image的时候直接截断了（我们是否可以改成截断？）
把板厚和坐标拆开？

输入的定义域是[-1,1] 我们把缺省值定为-1，然后使用[-0.9, 1]作为可行的区域，输出的时候把小于-0.9的全截断为-1（这样或许可以减少出错的概率）
另外一个方向是，把输出的坐标挪到关键点上，关键点的位置事先给定，相当于再加一个分类器变成离散的结果，可以保证结果的正确性

这样输入的定义仍然不太好，采用分开通道的模式，把是否缺省放在另外一个通道，缺省为0，不缺省为1，然后把所有的输入映射到[-1,1]
sample函数仍然需要改一下，明天再说，先下班
（看了一下，现在的loss又下降了一个台阶，不知道是不是输出参数变多还是模型更好了）

### 2023/4/26
早上与师姐讨论，发现Glide里面的text embed也用了mask的思想
sample函数内，mask需要取整，使用round函数（以0.5为分界线），输出坐标的时候，先clamp到[-1,1]，再放缩到原来的[0,10]，厚度也是一样

板的mask，sample输出缺省应该为-1而不是0(这个改完了)
现在模型输出的几个sample学习到了数据的大体分布特征，（例如在几个5，10，2.5之类的值附近），为了满足接口的要求，我们可以把表面上的点挪动到关键点上
关键面片由四个点组成，但是实际上生成的数据是不共面的，我们得开发一个基于4个点生成一个最接近的面的算法
即便这样，我们输出的数据仍然是不有效的（但是上面几点说明mask的方向是对的）我们为了让其能够更好的学习点的坐标，增加了更多的channel
|channel||
|--|--|--|--|--|--|--|--|--|
|x|[8,]|
|y|[8,]
|z|[8,]
|t|前四个点的厚度+后四个点的厚度
|mask|前四个点的mask+后四个点的mask
整个模型都要改了，开摆，明天再写，下班

### 2023/4/27
- [ ] 需要注意一下，thickness的输入由于师姐把数据处理的部分修改了，因此之后可能是要改的(getitem)
训练结果在数值上直接爆炸，我看看先把激活函数重新换成ReLU试试看(检查了半天似乎没有找到出问题的地方)
好像还是有问题，试试看条件的embed（下采样的时候不embed）损失函数变丝滑了
现在怀疑数值爆炸是训练epoch不够，loss在0.05左右的时候表现很好了（图像收敛的loss会更小）
现在的可能的几个方向：
1. 训练的epoch增加，模型的激活函数进行修改
2. 调整超参数或者模型，避免陷入局部最优，例如使用dropout层，减少学习率等
3. 训练的数据可以进行一定的增广，也可以提高模型的泛化能力，避免陷入局部最优
4. 可以使用梯度裁剪方法
5. 模型的feature值可以进一步增加（可能会有用）

先简单增广一下数据，明天早上看看效果如何

### 2023/4/29
增广后训练无法收敛，停在0.2左右附近
方案：增加batchnorm层，然后把激活函数改成GELU，增加feature值 （先试试）
**之后或许可以采用预训练的方式，以及去除池化层**

今天的训练结果表示，GELU确实可以把loss下降的过程弄的比较平滑
但是仍然存在的问题是，loss下降到0.2左右就会卡住
针对前天提出的几个方案，目前已经尝试过的有：
1. 激活函数进行修改
2. 学习率降了一半
3. 这点增广本来是想带来一些作用的，没想到现在起的都是反作用
4. feature增加了一倍

暂时还没做的
1. 预训练
2. 梯度裁剪
3. 调整模型，去除池化层
4. 数据增广上进行修改

### 2023/4/30
loss 在700多epoch的时候降到了0.17几
重新修改数据，面的交换去除，现在就先试试点的交换
> ⚠️注意，现在如果出现全部是-1的话交换点会出现重复数据，暂时先不处理这个
同时，这次还是提高一下学习率，不然真的太慢了（重新提升到1e-3）
坏了，把4/29的数据给覆盖了，怎么办23333
现在loss还是没法减少，是不是得考虑代码回滚了（x）
将修改数据进行点交换而不是面交换，发现可以收敛

### 2023/5/6
买显卡（技嘉？）
还是应该用wandb来可视化一下比较好
王欣月师姐的论文中的epoch很少，效果还行（写论文的时候可以参考一下）
师姐加上了范围的偏移，目前效果一般（可能是epoch太少了）
这一版训练的数据非常好，在训练集上都完全吻合，有一些面片点虽然没有对上，但是也是共面的
随便丢了一个刚算的新结构进去，厚度不一样，但是网络的输出还是相同的厚度，点也都是共面的
非常好

Todo:
- [x] 8:1:1 训练集，测试集，验证集
- [x] 规范化生成数据，格式参考师姐给的 saveNewUcGeomInfo 函数
- [ ] 查看并学习新项目内的网络结构，尤其是Attention层（在学了在学了）
- [ ] 后续需要对新的数据进行处理，增加不同厚度微结构的训练（5.10）


### 2023/5/7
师姐将生成的数据进行了检查，发现在生成的32组结构中，有19个结构是有效的，但是板厚还是不对（哪里不对？）
实际上从微结构训练集上的数据拿出来的效果都很不错，但是手动给出设计参数的结果就不太对
4_29_aug
<img src="readme_files/0507.png" width = "50%" />

根据师姐的反馈，这些微结构无效的原因有两条：1. 四点不共面 2. 三点共线
增加了几项todo
Todo:
- [ ] 增加三点共线转三个点的步骤
- [ ] 增加挪动关键点的过程：关键点坐标[0, 2.5 ,3.333333, 5.0 , 6.666667 , 7.5 ,10]
- [x] 最好还是能够直接要到下游任务的所有源代码
      要到了，但是环境配不起来（要命）
- [x] 王欣月师姐的论文
- [x] 把池化换成别的方式，如跨步卷积

另外一个想法是，有的点确实不在关键点上，是否可以设计一个从四个点产生一个最合适平面的算法（例如最近垂直距离，然后超过一定距离的就判断失效）
我们精确的引导信息实际上可能会被激活函数给抹掉，那么怎么样来结合回归问题的精确性以及一般神经网络里面激活函数的种种特性呢？

### 2023/5/8
增加了wandb可视化训练过程
将训练数据，测试数据，验证数据进行分离，训练和验证数据实时显示，测试数据保存为pth文件
去除卷积层进行训练->挂了，且效果一般
现在使用跨步卷积

### 2023/5/9
训练+写文章
师姐表示板状微结构别人做的生成很少，因为制造加工难度较高，现有的成熟算法都是基于TPMS或者是杆状的微结构
所以其实可能没有办法对比

### 2023/5/10
- [ ] 在数据库中加入不同厚度的板状微结构
- [ ] 今天应该能训练完，查看生成结果